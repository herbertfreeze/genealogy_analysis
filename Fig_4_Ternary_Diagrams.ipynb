{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from functions import *\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data Tables\n",
    "advises = pd.read_csv(\"data/advises.tsv\",sep='\\t')\n",
    "academic     = pd.read_csv(\"data/academic.tsv\",sep='\\t')\n",
    "academic[\"Full_Name\"] = academic.given_name + \" \" + academic.family_name\n",
    "degree_grant = pd.read_csv(\"data/degree_grant.tsv\",sep='\\t')\n",
    "school       = pd.read_csv(\"data/school.tsv\", sep='\\t')\n",
    "country      = pd.read_csv(\"data/country.tsv\", sep='\\t')\n",
    "degree1 = pd.read_csv(\"data/new_degree.tsv\", sep='\\t',keep_default_na=True)\n",
    "\n",
    "# Make Adjacency List & Graph\n",
    "adj_list = list(zip(advises[\"advisor\"], advises[\"advisee\"]))\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(adj_list)\n",
    "G_undirect = G.to_undirected()\n",
    "\n",
    "Fullname2ID = pd.Series(academic.academic_id.values, index=academic.Full_Name).to_dict()\n",
    "ID2Name = pd.Series(academic.Full_Name.values,index=academic.academic_id).to_dict()\n",
    "country2CN = pd.Series(country.country_name.values,index=country.country_id).to_dict()\n",
    "nx.set_node_attributes(G, ID2Name, 'full_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Fields Medalists\n",
    "medalists     = pd.read_csv(\"new_medalists.csv\",sep=',')\n",
    "medalist_IDs = []\n",
    "\n",
    "for i in medalists.Winner.values:\n",
    "    ID = Fullname2ID[i]\n",
    "    if i == \"Paul Cohen\":\n",
    "        ID = 6479\n",
    "    elif i == \"Michael Freedman\":\n",
    "        ID = 1365\n",
    "    elif i == \"Alan Baker\":\n",
    "        ID = 22765\n",
    "    elif ID == 230591:\n",
    "        ID = 93772\n",
    "    elif ID == 245820:\n",
    "        ID = 15779\n",
    "    elif ID == 211588:\n",
    "        ID = 6488\n",
    "    G.nodes()[ID][\"medalist\"] = 1\n",
    "    medalist_IDs.append(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step through medalists and get shortest path\n",
    "subgraph = defaultdict(int)\n",
    "for i, a in enumerate(medalist_IDs):\n",
    "    subgraph[a] = 1\n",
    "    for j, b in enumerate(medalist_IDs[i+1:]):\n",
    "        if nx.has_path(G_undirect,a,b):\n",
    "            path_nodes = nx.shortest_path(G_undirect,a,b)\n",
    "            for p in path_nodes:\n",
    "                subgraph[p] = 1\n",
    "subgraph_nodes = list(subgraph.keys())\n",
    "K = G.subgraph(subgraph_nodes) # Network of Elites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meso Analysis by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "academic2degree = pd.Series(degree1.degree_id.values,index=degree1.academic).to_dict()\n",
    "degree2school   = pd.Series(degree_grant.school.values,index=degree_grant.degree).to_dict()\n",
    "school2country  = pd.Series(school.country.values,index=school.school_id).to_dict()\n",
    "def ID2country(n1):\n",
    "    try:\n",
    "        degree_id  = academic2degree[n1]\n",
    "        school_id  = degree2school[ degree_id ]\n",
    "        country_id = school2country[ school_id ] \n",
    "        return country2CN[country_id]\n",
    "    except:\n",
    "        if n1 == 56371:\n",
    "            return \"Germany\"\n",
    "        \n",
    "edges_c = defaultdict(int)\n",
    "node_size = defaultdict(int)\n",
    "for n in K.nodes():\n",
    "    neighbors = K.neighbors(n)\n",
    "    node_size[ID2country(n)] += 1\n",
    "    for nei in neighbors:\n",
    "        edge_tuple = (ID2country(n) , ID2country(nei) )\n",
    "        edges_c[edge_tuple] += 1\n",
    "        \n",
    "C = nx.DiGraph()\n",
    "CC = nx.Graph()\n",
    "for k in edges_c.keys():\n",
    "    C.add_edge(k[0],k[1], weight = edges_c[k])\n",
    "    CC.add_edge(k[0],k[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract self-flow, inflow, outflow in dictionary form\n",
    "ethni_adj = nx.adj_matrix(C)\n",
    "ethni_adj = ethni_adj.toarray()\n",
    "eth2SF = {} # self-flow\n",
    "eth2IF = {} # in-flow\n",
    "eth2OF = {} # out-flow\n",
    "M = ethni_adj\n",
    "\n",
    "for i, D in enumerate(C.adjacency()):\n",
    "    n, __ = D\n",
    "    Self_Flow = M[i,i]\n",
    "    In_Flow   = np.sum(M[:,i]) - Self_Flow\n",
    "    Out_Flow  = np.sum(M[i,:]) - Self_Flow\n",
    "    \n",
    "    eth2SF[n] = Self_Flow\n",
    "    eth2IF[n] = In_Flow\n",
    "    eth2OF[n] = Out_Flow\n",
    "    \n",
    "# Format into Dirichlet Format\n",
    "points = {}\n",
    "color_dict = {}\n",
    "for k in eth2SF.keys():\n",
    "    NORM = eth2SF[k] + eth2IF[k] + eth2OF[k]\n",
    "    points[k] = np.array([eth2IF[k] , eth2OF[k] , eth2SF[k] ]) / NORM\n",
    "    if np.argmin(points[k]) == 0:\n",
    "        color_dict[k] = \"r\"\n",
    "    elif np.argmin(points[k]) == 1:\n",
    "        color_dict[k] = \"b\"\n",
    "\n",
    "        if points[k][0] == 1:\n",
    "            print(k)\n",
    "    else:\n",
    "        color_dict[k] = \"g\"\n",
    "        \n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "F = np.array([[1,0,0],\n",
    "              [0,1,0],\n",
    "              [0,0,1],\n",
    "#               [1/3,1/3,1/3],\n",
    "             ])\n",
    "F = SimplexTo2D(F)\n",
    "\n",
    "plt.fill(F.T[0],F.T[1],zorder=1,color=\"peachpuff\")\n",
    "label_list = [\"In-Flow\", \"Out-Flow\", \"Self-Flow\"]\n",
    "loc_adjustment = np.array([[-0.10, -0.06],\n",
    "                           [-0.1, 0.03],\n",
    "                           [-0.07,-0.06]\n",
    "                            ])\n",
    "\n",
    "for i in range(3): # plot each point + it's index as text above\n",
    "#     plt.scatter(*F[i], color='b',zorder=1,)\n",
    "    new_loc = F[i] + loc_adjustment[i]\n",
    "    plt.text(*new_loc, '%s' % (label_list[i]), size=22, zorder=1, color='r')\n",
    "\n",
    "\n",
    "points_2D = {}\n",
    "B = np.zeros((len(points.keys()),3))\n",
    "\n",
    "for i,k in enumerate(points.keys()):\n",
    "    p = np.copy(points[k])\n",
    "    points_2D[k] = SimplexTo2D(np.atleast_2d(p))\n",
    "    B[i,:] = np.copy(points[k])  \n",
    "    \n",
    "B = SimplexTo2D(B)\n",
    "B = B.T\n",
    "# plt.scatter(B[0],B[1],zorder=3)\n",
    "\n",
    "for k in points.keys():\n",
    "    plt.scatter(*points_2D[k][0], color= color_dict[k],zorder=3, s = 10+ node_size[k], alpha = 0.4)\n",
    "    location = points_2D[k][0] + np.array([0.008,0.001])\n",
    "    label = k\n",
    "    if k == \"Democratic Republic of the Congo\":\n",
    "        label = \"Congo\"\n",
    "        location += np.array([0.,-0.01])\n",
    "    elif k == \"Belgium\":\n",
    "        location += np.array([-0.07,0.010])\n",
    "    elif k == \"Argentina\":\n",
    "        location += np.array([0,-0.020])\n",
    "    elif k == \"Hungary\":\n",
    "        location += np.array([-0.095,-0.03])\n",
    "    elif k == \"Germany\":\n",
    "        location += np.array([-0.115,-0.03])\n",
    "    elif k == \"France\":\n",
    "        location += np.array([-0.02,0.01])\n",
    "    elif k == \"United Kingdom\":\n",
    "        location += np.array([-0.005,-0.035])\n",
    "    elif k == \"Poland\":\n",
    "        location += np.array([-0.005,0.01])\n",
    "    elif k == \"Greece\":\n",
    "        location += np.array([-0.03,0.016])\n",
    "    elif k == \"Spain\":\n",
    "        location += np.array([-0.03,0.016])\n",
    "    elif k == \"HongKong\":\n",
    "        location += np.array([-0.13,0.016])\n",
    "    elif k == \"Tunisia\":\n",
    "        location += np.array([0.0,-0.016])\n",
    "    elif k == \"Norway\":\n",
    "        continue\n",
    "    elif k == \"Croatia\":\n",
    "        continue\n",
    "        location += np.array([0.1,0.02])\n",
    "    elif k == \"Iran\":\n",
    "#         location += np.array([0.05,0.05])\n",
    "        label = \"Iran, etc\"\n",
    "        location += np.array([-0.01,0.024])\n",
    "#         continue\n",
    "    elif k == \"Uruguay\":\n",
    "        continue\n",
    "        location += np.array([0.11,0.05])\n",
    "    elif k == \"Norway\":\n",
    "        location += np.array([0.09,0.08])\n",
    "    elif k == \"Kenya\":\n",
    "        continue\n",
    "        location += np.array([0.14,-0.01])\n",
    "    elif k == \"Turkey\":\n",
    "        continue\n",
    "        location += np.array([0.14,-0.03])\n",
    "    elif k == \"Colombia\":\n",
    "        continue\n",
    "        location += np.array([0.0,0.024])\n",
    "        \n",
    "\n",
    "    plt.text(*location, '%s' % (label), size=14, zorder=1, color='k')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.xlim(-0.2,1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By Lingo-Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKI_FULL = pd.read_pickle(\"wiki_fullname.pkl\")\n",
    "Wiki_General = defaultdict(int)\n",
    "Wiki_Specific = defaultdict(int)\n",
    "for i, row in WIKI_FULL.iterrows():\n",
    "    n = row.race\n",
    "    general_region = n.split(\",\")[0] \n",
    "    specif_region  = n.split(\",\")[-1] \n",
    "    if specif_region == \"Jewish\":\n",
    "        n = (row.iloc[4:].sort_values(ascending = False).index[1] )\n",
    "        specif_region  = n.split(\",\")[-1]\n",
    "    \n",
    "    if specif_region == \"Muslim\":\n",
    "        specif_region = \"Arabic\"\n",
    "    elif specif_region == \"Hispanic\":\n",
    "        specif_region = \"Spanish\"\n",
    "    elif specif_region == \"British\":\n",
    "        specif_region = \"Anglo\"\n",
    "    \n",
    "    Wiki_General[ row.academic_id ]  = general_region\n",
    "    Wiki_Specific[ row.academic_id ] = specif_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Switched \n",
    "edges_c = defaultdict(int)\n",
    "node_size = defaultdict(int)\n",
    "edges_GEN = defaultdict(int)\n",
    "node_size_GEN = defaultdict(int)\n",
    "for n in K.nodes():\n",
    "    neighbors = K.neighbors(n)\n",
    "    node_size[Wiki_Specific[n]] += 1\n",
    "    node_size_GEN[Wiki_General[n]] += 1\n",
    "    for nei in neighbors:\n",
    "        edge_tuple = (Wiki_Specific[n], Wiki_Specific[nei])\n",
    "        edges_c[edge_tuple] += 1\n",
    "        edge_tuple = (Wiki_General[n], Wiki_General[nei])\n",
    "        edges_GEN[edge_tuple] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = nx.DiGraph()\n",
    "GEN = nx.DiGraph()\n",
    "CC = nx.Graph()\n",
    "for k in edges_c.keys():\n",
    "    C.add_edge(k[0],k[1], weight = edges_c[k])\n",
    "    CC.add_edge(k[0],k[1])\n",
    "for k in edges_GEN:\n",
    "    GEN.add_edge(k[0],k[1], weight = edges_GEN[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract self-flow, inflow, outflow in dictionary form\n",
    "ethni_adj = nx.adj_matrix(C)\n",
    "ethni_adj = ethni_adj.toarray()\n",
    "eth2SF = {} # self-flow\n",
    "eth2IF = {} # in-flow\n",
    "eth2OF = {} # out-flow\n",
    "M = ethni_adj\n",
    "\n",
    "for i, D in enumerate(C.adjacency()):\n",
    "    n, __ = D\n",
    "    Self_Flow = M[i,i]\n",
    "    In_Flow   = np.sum(M[:,i]) - Self_Flow\n",
    "    Out_Flow  = np.sum(M[i,:]) - Self_Flow\n",
    "    \n",
    "    eth2SF[n] = Self_Flow\n",
    "    eth2IF[n] = In_Flow\n",
    "    eth2OF[n] = Out_Flow\n",
    "    \n",
    "# Format into Dirichlet Format\n",
    "points = {}\n",
    "color_dict = {}\n",
    "for k in eth2SF.keys():\n",
    "    NORM = eth2SF[k] + eth2IF[k] + eth2OF[k]\n",
    "    points[k] = np.array([eth2IF[k] , eth2OF[k] , eth2SF[k] ]) / NORM\n",
    "    if np.argmin(points[k]) == 0:\n",
    "        color_dict[k] = \"r\"\n",
    "    elif np.argmin(points[k]) == 1:\n",
    "        color_dict[k] = \"b\"\n",
    "    else:\n",
    "        color_dict[k] = \"g\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "F = np.array([[1,0,0],\n",
    "              [0,1,0],\n",
    "              [0,0,1],\n",
    "#               [1/3,1/3,1/3],\n",
    "             ])\n",
    "F = SimplexTo2D(F)\n",
    "\n",
    "plt.fill(F.T[0],F.T[1],zorder=1, color = \"peachpuff\")\n",
    "label_list = [\"In-Flow\", \"Out-Flow\", \"Self-Flow\"]\n",
    "loc_adjustment = np.array([[-0.05, -0.05],\n",
    "                           [-0.05, 0.05],\n",
    "                           [-0.05,-0.05]\n",
    "                            ])\n",
    "\n",
    "for i in range(3): # plot each point + it's index as text above\n",
    "#     plt.scatter(*F[i], color='b',zorder=1,)\n",
    "    new_loc = F[i] + loc_adjustment[i]\n",
    "    plt.text(*new_loc, '%s' % (label_list[i]), size=22, zorder=1, color='r')\n",
    "\n",
    "points_2D = {}\n",
    "B = np.zeros((len(points.keys()),3))\n",
    "for i,k in enumerate(points.keys()):\n",
    "    p = np.copy(points[k])\n",
    "    points_2D[k] = SimplexTo2D(np.atleast_2d(p))\n",
    "    B[i,:] = np.copy(points[k])\n",
    "    \n",
    "B = SimplexTo2D(B)\n",
    "B = B.T\n",
    "# plt.scatter(B[0],B[1],zorder=3)\n",
    "\n",
    "for k in points.keys():\n",
    "    plt.scatter(*points_2D[k][0], color=color_dict[k],zorder=3 ,s = node_size[k]/2, alpha = 0.5)\n",
    "    label = k\n",
    "    location = points_2D[k][0] + np.array([0.008,0.001])\n",
    "    if k == \"IndianSubContinent\":\n",
    "        label = \"Indian/Asia\"\n",
    "    if k == \"Africans\":\n",
    "        label = \"African\"\n",
    "    elif k == \"EastEuropean\":\n",
    "#         label = \"Slavic\"\n",
    "        location += np.array([0,-0.02])\n",
    "    elif k == \"Anglo\":\n",
    "        location += np.array([-0.01,0.01])\n",
    "    elif k == \"Japanese\":\n",
    "        location += np.array([-0.06,0.03])\n",
    "    elif k == \"Germanic\":\n",
    "        location += np.array([-0.06,0.03])\n",
    "    plt.text(*location, '%s' % (label), size=16, zorder=1, color='k')\n",
    "\n",
    "    \n",
    "# Extract self-flow, inflow, outflow in dictionary form\n",
    "ethni_adj = nx.adj_matrix(GEN)\n",
    "ethni_adj = ethni_adj.toarray()\n",
    "eth2SF = {} # self-flow\n",
    "eth2IF = {} # in-flow\n",
    "eth2OF = {} # out-flow\n",
    "M = ethni_adj\n",
    "\n",
    "for i, D in enumerate(GEN.adjacency()):\n",
    "    n, __ = D\n",
    "    Self_Flow = M[i,i]\n",
    "    In_Flow   = np.sum(M[:,i]) - Self_Flow\n",
    "    Out_Flow  = np.sum(M[i,:]) - Self_Flow\n",
    "    \n",
    "    eth2SF[n] = Self_Flow\n",
    "    eth2IF[n] = In_Flow\n",
    "    eth2OF[n] = Out_Flow\n",
    "    \n",
    "# Format into Dirichlet Format\n",
    "points_GEN = {}\n",
    "color_dict_GEN = {}\n",
    "for k in eth2SF.keys():\n",
    "    NORM = eth2SF[k] + eth2IF[k] + eth2OF[k]\n",
    "    points_GEN[k] = np.array([eth2IF[k] , eth2OF[k] , eth2SF[k] ]) / NORM\n",
    "    if np.argmin(points_GEN[k]) == 0:\n",
    "        color_dict_GEN[k] = \"r\"\n",
    "    elif np.argmin(points_GEN[k]) == 1:\n",
    "        color_dict_GEN[k] = \"b\"\n",
    "    else:\n",
    "        color_dict_GEN[k] = \"g\"    \n",
    "    \n",
    "points_2D_GEN = {}\n",
    "for i,k in enumerate(points_GEN.keys()):\n",
    "    p = np.copy(points_GEN[k])\n",
    "    points_2D_GEN[k] = SimplexTo2D(np.atleast_2d(p))\n",
    "\n",
    "labeled = defaultdict(int)\n",
    "for k in points_GEN.keys():\n",
    "    # Label color\n",
    "#     if color_dict_GEN[k] == \"r\" and not label_bool[\"r\"] == 1:\n",
    "    if color_dict_GEN[k] == \"r\":\n",
    "        plt.scatter(*points_2D_GEN[k][0], color=color_dict_GEN[k],zorder=3,s = 300 , alpha=1.0, label = \"Out-/Self-Flow\")\n",
    "        labeled[\"r\"] = 1\n",
    "#     elif color_dict_GEN[k] == \"g\"and not label_bool[\"g\"] == 1:\n",
    "    elif color_dict_GEN[k] == \"g\":\n",
    "        plt.scatter(*points_2D_GEN[k][0], color=color_dict_GEN[k],zorder=3,s = 300 , alpha=1.0, label = \"In-/Out-Flow\")\n",
    "        labeled[\"g\"] = 1\n",
    "#     if color_dict_GEN[k] == \"b\" and not label_bool[\"b\"] == 1:\n",
    "    if color_dict_GEN[k] == \"b\":\n",
    "        plt.scatter(*points_2D_GEN[k][0], color=color_dict_GEN[k],zorder=3,s = 300 , alpha=1.0, label = \"In-/Self-Flow\")\n",
    "        labeled[\"b\"] = 1    \n",
    "    label = k\n",
    "    location = points_2D_GEN[k][0] + np.array([0.02,-0.02])\n",
    "    if k == \"Asian\":\n",
    "        location += np.array([-0.06,-0.035])\n",
    "    if k == \"GreaterAfrican\":\n",
    "        location += np.array([-0.02,0.035])\n",
    "    plt.text(*location, '%s' % (label), size=20, zorder=1, color='k')\n",
    "    print(k)\n",
    "\n",
    "plt.legend(fontsize=20)\n",
    "    \n",
    "plt.axis('off')\n",
    "plt.xlim(-0.2,1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
